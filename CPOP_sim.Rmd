---
title: "CPOP_sim"
author: "Kevin Wang"
date: "21/09/2019"
output: html_document
---

The deficiency of this simulation is that there is no validation data for CPOP because it used up both data.


```{r}
library(tidyverse)
library(mvtnorm)
library(glmnet)
library(Matrix)

theme_set(theme_classic(18) +
          theme(legend.position = "bottom"))
```


```{r}
n = 500
p = 40
set.seed(1234)
variables = sprintf("X%02d", 1:p)
```


# Switching mu
```{r}
mu1 = runif(p, -5, 5)
switch_mu1 = rbinom(p, size = 1, prob = 0.3)
mu2 = map2_dbl(.x = mu1, 
               .y = switch_mu1,
               .f = ~ ifelse(.y == 1, runif(1, -5, 5), .x))


coef_tibble = tibble(
  variables,
  mu1,
  switch_mu1,
  mu2
)

coef_tibble %>% 
  ggplot(aes(x = mu1, y = mu2, 
             colour = factor(switch_mu1))) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, colour = "red")
```


# Switching sigma 

```{r}
sigma12 = matrix(rnorm(p^2), ncol = p) 
sigma1 = t(sigma12) %*% sigma12
dimnames(sigma1) = list(variables, variables)
# sigma2 = sigma1
sigma12 = matrix(rnorm(p^2), ncol = p) 
sigma2 = t(sigma12) %*% sigma12
dimnames(sigma2) = list(variables, variables)
```


```{r}
library(ggcorrplot)
cor1 = cov2cor(sigma1)
ggcorrplot(cor1,
           hc.order = FALSE,
           type = "lower",
           outline.color = "white")
```



```{r}
beta1 = rbeta(p, shape1 = 0.1, shape2 = 0.5)
switch_beta1 = rbinom(p, size = 1, prob = 0.2)
beta2 = map2_dbl(.x = beta1, 
                 .y = switch_beta1,
                 .f = ~ ifelse(.y == 1, 
                               rbeta(1, shape1 = 0.1, shape2 = 0.5),
                               .x))

coef_tibble = coef_tibble %>% 
  dplyr::mutate(beta1, switch_beta1, beta2)


coef_tibble %>% 
  ggplot(aes(x = beta1, y = beta2, 
             colour = factor(switch_beta1))) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, colour = "red")
```


```{r}
x1 = mvtnorm::rmvnorm(n = n, mean = mu1, sigma = sigma1)
x2 = mvtnorm::rmvnorm(n = n, mean = mu2, sigma = sigma2)
colnames(x1) = colnames(x2) = variables

y1 = x1 %*% beta1
y2 = x2 %*% beta2
```



# naive cv.glmnet
```{r}
naive1 = glmnet::cv.glmnet(x = x1, y = y1, alpha = 0)
naive2 = glmnet::cv.glmnet(x = x2, y = y2, alpha = 0)
```


## Compare coef
```{r}
coef_tibble = coef_tibble %>% 
  left_join(
    CPOP::get_lasso_coef(naive1, s = "lambda.min", tibble = TRUE) %>% 
      dplyr::rename(variables = feature_name,
                    beta_hat1 = beta), 
    by = c("variables")) %>% 
  left_join(
    CPOP::get_lasso_coef(naive2, s = "lambda.min", tibble = TRUE) %>% 
      dplyr::rename(variables = feature_name,
                    beta_hat2 = beta), 
    by = c("variables")) %>% 
  dplyr::mutate(beta_hat1 = coalesce(beta_hat1, 0),
                beta_hat2 = coalesce(beta_hat2, 0))

coef_tibble %>% 
  ggplot(aes(x = beta_hat1, y = beta_hat2, 
             colour = factor(switch_beta1))) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, colour = "red")
```


## Prediction on x1
```{r}
pred_naive1_x1 = predict(naive1, newx = x1, s = "lambda.min")
pred_naive2_x1 = predict(naive2, newx = x1, s = "lambda.min") 
cor(pred_naive1_x1, pred_naive2_x1)
plot(pred_naive1_x1, pred_naive2_x1)
```

## Prediction on x2
```{r}
pred_naive1_x2 = predict(naive1, newx = x2, s = "lambda.min")
pred_naive2_x2 = predict(naive2, newx = x2, s = "lambda.min")
cor(pred_naive1_x2, pred_naive2_x2)
plot(pred_naive1_x2, pred_naive2_x2)
```


```{r}
library(CPOP)
CPOP_model = CPOP::cpop_model(z1 = x1, 
                              z2 = x2, 
                              y1 = y1, 
                              y2 = y2, 
                              w = CPOP::compute_weights(x1, x2),
                              alpha = 0.1,
                              family = "gaussian")

coef_tibble = coef_tibble %>% 
  dplyr::mutate(
    CPOP_feature = variables %in% CPOP_model$feature
  )


coef_tibble %>% 
  ggplot(aes(x = beta1, y = beta2, 
             colour = factor(CPOP_feature))) +
  geom_point(size = 3) +
  geom_abline(slope = 1, intercept = 0, colour = "red")

CPOP::plot_cpop_coef(CPOP_model, type = "point")
CPOP::plot_cpop_coef(CPOP_model, type = "bar")

pred_cpop1_x1 = CPOP::predict_cpop(CPOP_model, newz = x1, 
                                   s = "lambda.min", model_number = 1)
pred_cpop2_x1 = CPOP::predict_cpop(CPOP_model, newz = x1,
                                   s = "lambda.min", model_number = 2)

plot(pred_cpop1_x1, pred_cpop2_x1)
cor(pred_cpop1_x1, pred_cpop2_x1)
abline(a = 0, b = 1, col = "red")
```

# Integration of CPOP with prediction correlation lambda selection 

```{r}
pred_cpop1_x1_mat = predict(CPOP_model$en1, 
                            newx = x1[,CPOP_model$feature], 
                            s = CPOP_model$en1$lambda)
pred_cpop2_x1_mat = predict(CPOP_model$en2, 
                            newx = x1[,CPOP_model$feature], 
                            s = CPOP_model$en1$lambda)

pred_cpop1_x2_mat = predict(CPOP_model$en1, 
                            newx = x2[,CPOP_model$feature], 
                            s = CPOP_model$en1$lambda)
pred_cpop2_x2_mat = predict(CPOP_model$en2, 
                            newx = x2[,CPOP_model$feature], 
                            s = CPOP_model$en1$lambda)
##############################################
one_vs_mat_id = function(x, mat){
  purrr::map_dbl(1:100,
                 ~ tryCatch(identityDist(x, mat[,.x]), error = function(e){10}))
}


id_pred_x1_twocpop = purrr::map(1:100,
                                ~ one_vs_mat_id(
                                  pred_cpop1_x1_mat[,.x],
                                  pred_cpop2_x1_mat)) %>%
  do.call(cbind, .) %>% abs()

which(id_pred_x1_twocpop == min(id_pred_x1_twocpop), arr.ind = TRUE)

id_pred_x1_twocpop %>% 
  d3heatmap::d3heatmap(Rowv = FALSE, Colv = FALSE)

plot(pred_cpop1_x1_mat[,1], pred_cpop2_x1_mat[,3])
abline(a = 0, b = 1, col = "red")
cor(pred_cpop1_x1_mat[,1], pred_cpop2_x1_mat[,3])
####################################################
new_iden_dist = function(x, y){
  CPOP::identityDist(x, y) +
    abs(e1071::skewness(x-y))
}


one_vs_mat_nid = function(x, mat){
  purrr::map_dbl(1:100,
                 ~ tryCatch(new_iden_dist(x, mat[,.x]), error = function(e){10}))
}


nid_pred_x1_twocpop = purrr::map(1:100,
                                 ~ one_vs_mat_nid(
                                   pred_cpop1_x1_mat[,.x],
                                   pred_cpop2_x1_mat)) %>%
  do.call(cbind, .) %>% abs()

which(nid_pred_x1_twocpop == min(nid_pred_x1_twocpop), arr.ind = TRUE)

nid_pred_x1_twocpop %>% 
  d3heatmap::d3heatmap(Rowv = FALSE, Colv = FALSE, colors = "Blues")

plot(pred_cpop1_x1_mat[,1], pred_cpop2_x1_mat[,6])
abline(a = 0, b = 1, col = "red")
cor(pred_cpop1_x1_mat[,1], pred_cpop2_x1_mat[,6])

##################################################
one_vs_mat_ttest = function(x, mat){
  purrr::map_dbl(1:100,
                 ~ tryCatch(t.test(x, mat[,.x])$statistic, error = function(e){1000}))
}

ttest_pred_x1_twocpop = purrr::map(1:100,
                                   ~ one_vs_mat_ttest(
                                     pred_cpop1_x1_mat[,.x],
                                     pred_cpop2_x1_mat)) %>%
  do.call(cbind, .) %>% abs()

which(ttest_pred_x1_twocpop == min(ttest_pred_x1_twocpop), arr.ind = TRUE)

ttest_pred_x1_twocpop %>% 
  d3heatmap::d3heatmap(Rowv = FALSE, Colv = FALSE, colors = "Blues")
##################################################

plot(log(CPOP_model$en1$lambda), ttest_pred_x1_twocpop[52, ], type = "l")
abline(v = log(CPOP_model$en1$lambda.min), col = "red")
abline(v = log(CPOP_model$en1$lambda[64]), col = "blue")

plot(pred_cpop1_x1_mat[,52], pred_cpop2_x1_mat[,64])
abline(a = 0, b = 1, col = "red")
cor(pred_cpop1_x1_mat[,52], pred_cpop2_x1_mat[,64])
```

